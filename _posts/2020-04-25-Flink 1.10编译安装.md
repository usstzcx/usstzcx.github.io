---
layout:     post
title:      Flink 1.10 on yarn
subtitle:   Flink安装
date:       2020-04-25
author:     change
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - 大数据
    - 实时计算
    - Flink
---
# Flink on yarn 安装

## 一、软件准备

1.下载flink安装包。我使用的是最新的flink 1.10.0。这里需要注意的是，flink on yarn需要flink的安装包以及和hadoop集成的jar包，官方已经预编译了一些版本，并且flink也是与scala版本对应。

`flink-1.10.0-bin-scala_2.11.tgz`

因为我们需要安装在yarn上，flink从1.8版本后apache就不提供hadoop的预编译包，目前官网仅提供了hadoop 2.4.1、2.6.5、2.7.5、2.8.3这几个版本的flink-shaded-hadoop预编译jar包。具体如下：

![3](https://github.com/usstzcx/usstzcx.github.io/tree/master/img/3.png)

如果你使用的是上面这些版本，那么直接下载使用即可。但是我们的hadoop集群版本是2.7.2，所以需要重新编译对应的jar包。

下载 Flink-shade 10.0的src源码。

`flink-shaded-10.0-src.tgz`

推荐使用国内镜像下载

https://mirrors.tuna.tsinghua.edu.cn/apache/flink/flink-1.10.0/ 

2.flink依赖jdk和scala，需要提前安装。检查确认是否安装

`java -version`

![1](https://github.com/usstzcx/usstzcx.github.io/tree/master/img/1.png)

`scala -version`

![2](https://github.com/usstzcx/usstzcx.github.io/tree/master/img/2.png)

3.软件编译需要maven，检查maven是否安装

`mvn -v`

![4](https://github.com/usstzcx/usstzcx.github.io/tree/master/img/4.png)

由于大家都懂的原因，建议将maven的源配置为阿里云仓库。修改maven安装目录下的settings.xml文件。

```shell
vim settings.xml
#修改maven仓库
<mirror>
    <id>nexus-aliyun</id>
    <mirrorOf>central</mirrorOf>
    <name>Nexus aliyun</name>
    <url>http://maven.aliyun.com/nexus/content/groups/public</url>
</mirror>
:wq
```

4.修改pom文件

首先明确下我们的目标，我们的目标是要让flink在hadoop上跳舞。所以我们对于1.8以后的版本我们要自行编译出来对应我们需要的hadoop版本的二进制包。但是官方提供的shaded的源码中缺少一个依赖commons-cli，我们需要将以下依赖，添加到flink-shaded-7.0/flink-shaded-hadoop-2-uber/pom.xml 中的 dependencyManagement 标签中，不然后续flink启动yarn session或直接向yarn提交任务都会出现NoSuchMethodError的错误。

```shell
cd flink-shaded-10.0/flink-shaded-hadoop-2-parent/flink-shaded-hadoop-2-uber
vim pom.xml
#在dependencyManagement的dependencies标签内增加下面内容
<dependency>
    <groupId>commons-cli</groupId>
    <artifactId>commons-cli</artifactId>
    <version>1.3.1</version>
</dependency>
:wq
```

5.编译

进入flink-shaded-10.0源码根目录，执行

`mvn clean install -DskipTests -Dhadoop.version=2.7.2`

一切顺利的话大概十几分钟后看到以下画面

![mv](https://github.com/usstzcx/usstzcx.github.io/tree/master/img/mv.png)

至此，编译完成，进入maven的仓库目录

`cd /var/root/.m2/repository/org/apache/flink/flink-shaded-hadoop-2-uber/2.7.2-10.0`

可以看到flink-shaded-hadoop-2-uber-2.7.2-10.0.jar，这个就是flink on yarn需要的二进制jar包。

## 二、软件安装

注意：flink on yarn需要依赖zookeeper和hadoop，需要提前安装配置，并注意版本依赖

1.解压

`tar -zvxf flink-1.10.0-bin-scala_2.11.tgz`

2.拷贝flink-hadoop集成jar包

将第一步编译得到的jar包分发到flink安装目录的lib文件夹下

`cp flink-shaded-hadoop-2-uber-2.7.2-10.0.jar flnik-1.10.0/lib/`

3.配置环境变量

```shell
vim /etc/profile
#添加flink环境变量
export FLINK_HOME=/data/app/flink-1.10.0
export PATH=$FLINK_HOME/bin:$PATH
:wq
source /etc/profile
```

4.修改flink配置

可以参考官网提供的example(HA配置)

https://ci.apache.org/projects/flink/flink-docs-release-1.10/ops/jobmanager_high_availability.html

相关配置文件

```shell
flink-conf.yaml
masters
slaves
zoo.cfg
```

flink-conf.yaml

```
################################################################################
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
# limitations under the License.
################################################################################


#==============================================================================
# Common
#==============================================================================

# The external address of the host on which the JobManager runs and can be
# reached by the TaskManagers and any clients which want to connect. This setting
# is only used in Standalone mode and may be overwritten on the JobManager side
# by specifying the --host <hostname> parameter of the bin/jobmanager.sh executable.
# In high availability mode, if you use the bin/start-cluster.sh script and setup
# the conf/masters file, this will be taken care of automatically. Yarn/Mesos
# automatically configure the host name based on the hostname of the node where the
# JobManager runs.

#jobmanager主机名
jobmanager.rpc.address: hszk01

# The RPC port where the JobManager is reachable.

jobmanager.rpc.port: 6123


# The heap size for the JobManager JVM
#JVM堆内存，根据机器配置调整
jobmanager.heap.size: 1024m


# The total process memory size for the TaskManager.
#
# Note this accounts for all memory usage within the TaskManager process, including JVM metaspace and other overhead.
#TaskManager总内存，yarn模式建议配置此项
taskmanager.memory.process.size: 1688m

# To exclude JVM metaspace and overhead, please, use total Flink memory size instead of 'taskmanager.memory.process.size'.
# It is not recommended to set both 'taskmanager.memory.process.size' and Flink memory.

# taskmanager.memory.flink.size: 512m

# The number of task slots that each TaskManager offers. Each slot runs one parallel pipeline.

taskmanager.numberOfTaskSlots: 4

# The parallelism used for programs that did not specify and other parallelism.

parallelism.default: 1

# The default file system scheme and authority.
#
# By default file paths without scheme are interpreted relative to the local
# root file system 'file:///'. Use this to override the default and interpret
# relative paths relative to a different file system,
# for example 'hdfs://mynamenode:12345'
#
# fs.default-scheme

#==============================================================================
# High Availability
#==============================================================================

# The high-availability mode. Possible options are 'NONE' or 'zookeeper'.
#
high-availability: zookeeper

# The path where metadata for master recovery is persisted. While ZooKeeper stores
# the small ground truth for checkpoint and leader election, this location stores
# the larger objects, like persisted dataflow graphs.
#
# Must be a durable file system that is accessible from all nodes
# (like HDFS, S3, Ceph, nfs, ...)
#
high-availability.storageDir: hdfs://hdfsCluster/flink/ha/

# The list of ZooKeeper quorum peers that coordinate the high-availability
# setup. This must be a list of the form:
# "host1:clientPort,host2:clientPort,..." (default clientPort: 2181)
#
high-availability.zookeeper.quorum: hszk01:2181,hszk02:2181,hszk03:2181


# ACL options are based on https://zookeeper.apache.org/doc/r3.1.2/zookeeperProgrammers.html#sc_BuiltinACLSchemes
# It can be either "creator" (ZOO_CREATE_ALL_ACL) or "open" (ZOO_OPEN_ACL_UNSAFE)
# The default value is "open" and it can be changed to "creator" if ZK security is enabled
#
# high-availability.zookeeper.client.acl: open
high-availability.zookeeper.path.root: /flink
#==============================================================================
# Fault tolerance and checkpointing
#==============================================================================

# The backend that will be used to store operator state checkpoints if
# checkpointing is enabled.
#
# Supported backends are 'jobmanager', 'filesystem', 'rocksdb', or the
# <class-name-of-factory>.
#
state.backend: filesystem

# Directory for checkpoints filesystem, when using any of the default bundled
# state backends.
#
state.checkpoints.dir: hdfs://hdfsCluster/flink/checkpoints

# Default target directory for savepoints, optional.
#
state.savepoints.dir: hdfs://hdfsCluster/flink/savepoints

# Flag to enable/disable incremental checkpoints for backends that
# support incremental checkpoints (like the RocksDB state backend).
#
# state.backend.incremental: false

# The failover strategy, i.e., how the job computation recovers from task failures.
# Only restart tasks that may have been affected by the task failure, which typically includes
# downstream tasks and potentially upstream tasks if their produced data is no longer available for consumption.

jobmanager.execution.failover-strategy: region

#==============================================================================
# Rest & web frontend
#==============================================================================

# The port to which the REST client connects to. If rest.bind-port has
# not been specified, then the server will bind to this port as well.
#
rest.port: 8081

# The address to which the REST client will connect to
#
#rest.address: 0.0.0.0

# Port range for the REST and web server to bind to.
#
#rest.bind-port: 8080-8090

# The address that the REST & web server binds to
#
#rest.bind-address: 0.0.0.0

# Flag to specify whether job submission is enabled from the web-based
# runtime monitor. Uncomment to disable.

web.submit.enable: true

#==============================================================================
# Advanced
#==============================================================================

# Override the directories for temporary files. If not specified, the
# system-specific Java temporary directory (java.io.tmpdir property) is taken.
#
# For framework setups on Yarn or Mesos, Flink will automatically pick up the
# containers' temp directories without any need for configuration.
#
# Add a delimited list for multiple directories, using the system directory
# delimiter (colon ':' on unix) or a comma, e.g.:
#     /data1/tmp:/data2/tmp:/data3/tmp
#
# Note: Each directory entry is read from and written to by a different I/O
# thread. You can include the same directory multiple times in order to create
# multiple I/O threads against that directory. This is for example relevant for
# high-throughput RAIDs.
#
io.tmp.dirs: /data/app/flink-1.10.0/tmp
env.log.dir: /data/app/flink-1.10.0/log

# The classloading resolve order. Possible values are 'child-first' (Flink's default)
# and 'parent-first' (Java's default).
#
# Child first classloading allows users to use different dependency/library
# versions in their application than those in the classpath. Switching back
# to 'parent-first' may help with debugging dependency issues.
#
# classloader.resolve-order: child-first

# The amount of memory going to the network stack. These numbers usually need
# no tuning. Adjusting them may be necessary in case of an "Insufficient number
# of network buffers" error. The default min is 64MB, the default max is 1GB.
#
#taskmanager.memory.network.fraction: 0.1
#taskmanager.memory.network.min: 64mb
#taskmanager.memory.network.max: 1gb
#taskmanager.cpu.cores: 1
#taskmanager.memory.task.heap.size: 256m
#taskmanager.memory.managed.size: 256m
fs.hdfs.hadoopconf: /data/app/hadoop-2.7.2/etc/hadoop/

#==============================================================================
# Flink Cluster Security Configuration
#==============================================================================

# Kerberos authentication for various components - Hadoop, ZooKeeper, and connectors -
# may be enabled in four steps:
# 1. configure the local krb5.conf file
# 2. provide Kerberos credentials (either a keytab or a ticket cache w/ kinit)
# 3. make the credentials available to various JAAS login contexts
# 4. configure the connector to use JAAS/SASL

# The below configure how Kerberos credentials are provided. A keytab will be used instead of
# a ticket cache if the keytab path and principal are set.

# security.kerberos.login.use-ticket-cache: true
# security.kerberos.login.keytab: /path/to/kerberos/keytab
# security.kerberos.login.principal: flink-user

# The configuration below defines which JAAS login contexts

# security.kerberos.login.contexts: Client,KafkaClient

#==============================================================================
# ZK Security Configuration
#==============================================================================

# Below configurations are applicable if ZK ensemble is configured for security

# Override below configuration to provide custom ZK service name if configured
# zookeeper.sasl.service-name: zookeeper

# The configuration below must match one of the values set in "security.kerberos.login.contexts"
# zookeeper.sasl.login-context-name: Client

#==============================================================================
# HistoryServer
#==============================================================================

# The HistoryServer is started and stopped via bin/historyserver.sh (start|stop)

# Directory to upload completed jobs to. Add this directory to the list of
# monitored directories of the HistoryServer as well (see below).
jobmanager.archive.fs.dir: hdfs://hdfsCluster/flink/completed-jobs/

# The address under which the web-based HistoryServer listens.
historyserver.web.address: 0.0.0.0

# The port under which the web-based HistoryServer listens.
#historyserver.web.port: 8082

# Comma separated list of directories to monitor for completed jobs.
historyserver.archive.fs.dir: hdfs://hdfsCluster/flink/completed-jobs/

# Interval in milliseconds for refreshing the monitored directories.
historyserver.archive.fs.refresh-interval: 10000

#配置yarn重试次数
yarn.application-attempts: 10
```

zoo.cfg

```
################################################################################
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
# limitations under the License.
################################################################################

# The number of milliseconds of each tick
tickTime=2000

# The number of ticks that the initial  synchronization phase can take
initLimit=10

# The number of ticks that can pass between  sending a request and getting an acknowledgement
syncLimit=5

# The directory where the snapshot is stored.
dataDir=/data/app/flink-1.10.0/zkdata
dataLogDir=/data/app/flink-1.10.0/zklog

# The port at which the clients will connect
clientPort=2181

# ZooKeeper quorum peers
server.1=hszk01:2888:3888
server.2=hszk02:2888:3888
server.3=hszk03:2888:3888
```

masters

```
hszk01:8081
hszk02:8081
```

slaves

```
hszk01
hszk02
hszk03
```

将修改好的配置文件分发到其他flink节点

因为配置了flink的HA需要修改yarn的作业最大重试次数

yarn-site.xml

```
<property>
  <name>yarn.resourcemanager.am.max-attempts</name>
  <value>4</value>
  <description>
    The maximum number of application attempts. It's a global
    setting for all application masters. Each application master can specify
    its individual maximum number of application attempts via the API, but the
    individual number cannot be more than the global upper bound. If it is,
    the resourcemanager will override it. The default number is set to 2, to
    allow at least one retry for AM.
  </description>
</property>
```

修改完分别在两台namenode执行以下指令，注意替换主机名和端口

```
yarn rmadmin -fs hdfs://hsnn01:9000 -refreshSuperUserGroupsConfiguration
yarn rmadmin -fs hdfs://hsnn02:9000 -refreshSuperUserGroupsConfiguration
```

将修改完的Flink配置文件分发到其他flink节点

## 三、启动验证

1.启动flink集群

```
cd /data/app/flink-1.10.0/bin
./start-cluster.sh
```

启动成功可以看到如下情况

![1585186608597](https://github.com/usstzcx/usstzcx.github.io/tree/master/img/1585186608597.png)

查看flink进程

`jps`

![1585186705781](https://github.com/usstzcx/usstzcx.github.io/tree/master/img/1585186705781.png)

查看web页面

`http://22.188.12.56:8081`

![1585186786207](https://github.com/usstzcx/usstzcx.github.io/tree/master/img/1585186786207.png)

2.程序验证

进入flink的bin目录，提交wordcount程序(flink on yarn模式)

在这里需要注意：所有的hadoop datanode机器需要安装flink客户端并创建对应目录，要不然会运行报错。如果提示找不到相关类，可能为jersey相关类，只需将相关jar包放到flink的lib目录下即可。		

![1585530193079](https://github.com/usstzcx/usstzcx.github.io/tree/master/img/1585530193079.png)

`./flink run -m yarn-cluster ../examples/batch/WordCount.jar --input hdfs://hdfsCluster/project/HDSS/conf/stream.properties --output hdfs://hdfsCluster/project/HDSS/output`

![1585295701545](https://github.com/usstzcx/usstzcx.github.io/tree/master/img/1585295701545.png)

查看yarn

![1585295741344](https://github.com/usstzcx/usstzcx.github.io/tree/master/img/1585295741344.png)

查看程序运行结果

`hadoop fs -cat /project/HDSS/output`

![1585297309735](https://github.com/usstzcx/usstzcx.github.io/tree/master/img/1585297309735.png)

flink集群模式提交作业

`./flink run ../examples/batch/WordCount.jar --input file:///data/app/flink-1.10.0/README.txt --output file:///data/app/flink-1.10.0/output`

![1585534589143](https://github.com/usstzcx/usstzcx.github.io/tree/master/img/1585534589143.png)

查看程序运行结果

![1585534660396](https://github.com/usstzcx/usstzcx.github.io/tree/master/img/1585534660396.png)

查看flink管理界面

![1585534712323](https://github.com/usstzcx/usstzcx.github.io/tree/master/img/1585534712323.png)

至此，flink安装完成。
