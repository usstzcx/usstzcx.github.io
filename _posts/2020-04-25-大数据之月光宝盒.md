---
layout:     post
title:      大数据之月光宝盒
subtitle:   大数据之月光宝盒
date:       2020-04-25
author:     change
header-img: img/makalong.jpg
catalog: true
tags:
    - 大数据
---
# 大数据之月光宝盒
读史使人明智

大数据是近些年来特别火的一个话题，但是近两年逐渐被人工智能取代了。不过大数据现在已经发展为新基建不可或缺的基础设施。今天我们来看看大数据的前世今生，大数据是怎么诞生的、怎么发展的，将来会是什么样。
##大数据之三驾马车
今天我们常说的大数据技术，其实起源于谷歌的“三驾马车”：谷歌文件系统（The Google File System; http://labs.google.com/papers/gfs-sosp2003.pdf）、MapReduce（MapReduce: Simplifed Data Processing on Large Clusters; http://labs.google.com/papers/mapreduce-osdi04.pdf）和 BigTable（Bigtable: A Distributed Storage System for Structured Data;http://labs.google.com/papers/bigtable-osdi06.pdf），这三篇论文分别发表于 2003年、2004年和 2007年。

###GFS

GFS是一个分布式文件系统，用来存储大量的较大文件，它可以在廉价的硬件上实现存储文件，并做到容错性，并且针对多个客户同时访问提供比较有竞争力的性能。

其中的重点是：

把一个较大的文件切分成不同的单元块。
把每一个单元块存储在ChunkServer上，并且每一块都会复制在多个ChunkServer服务器上。
每一个文件包含多少块和哪些块这些元数据存储在GFS Master服务器上。
###MapReduce
MapReduce是一个处理大数据集的编程模型。它通过map函数把基于行的输入转化成不同的键值对，再通过reduce函数把这些键值对针对相同的键进行聚合，并在聚合的过程中进行相应的计算。

其中的重点是：

如何分割基于行的源文件。
在map阶段如何把行数据映射成键值对。
对大数据集如何进行partition。
在reduce阶段如何进行响应的逻辑计算并输出结果。
###BigTable
Bigtable是一个可以管理结构化数据的分布式存储系统，它本身支持水平的横向扩展，通过使用成千上万的连接服务器，来支持PB量级的数据处理。

其中的重点是：

Chubby服务器存储SSTable根的数据信息。
Tablet server的水平扩展以及分裂。
SSTable的存储结构。
列式存储结构，RowKey以及列簇的设计。
LSM Tree的数据结构以及特点。

大家都知道google是做搜索引擎的，而搜索引擎主要就做两件事情，一个是网页抓取，一个是索引构建，而在这个过程中，有大量的数据需要存储和计算。这“三驾马车”其实就是用来解决这个问题的，你从介绍中也能看出来，一个文件系统、一个计算框架、一个数据库系统。

现在你听到分布式、大数据之类的词，肯定一点儿也不陌生。但你要知道，在2004年那会儿，整个互联网还处于懵懂时代，Google发布的论文实在是让业界为之一振，大家恍然大悟，原来还可以这么玩。

因为那个时间段，大多数公司的关注点其实还是聚焦在单机上，在思考如何提升单机的性能，寻找更贵更好的服务器。而Google的思路是部署一个大规模的服务器集群，通过分布式的方式将海量数据存储在这个集群上，然后利用集群上的所有机器进行数据计算。 这样，Google其实不需要买很多很贵的服务器，它只要把这些普通的机器组织到一起，就非常厉害了。

Google作为互联网泡沫破灭后第一次上市的大型 IT公司，它的市值在上市之后飞速增长。原因在于，Google的广告业务做得非常成功，而广告业务成功的很大一部分原因是它用了大数据技术。当时，很多相关的互联网企业因此都认为大数据是改变自己命运的机会，因此纷纷加入大数据圈子，入局的有微软、阿里巴巴、雅虎、Facebook、LinkedIn、Twitter等公司。

##Hadoop
谷歌发表论文时，Lucene开源项目的创始人Doug Cutting正在开发开源搜索引擎Nutch，阅读了Google的论文后，他非常兴奋，紧接着就根据论文原理初步实现了类似GFS和MapReduce的功能。

两年后的2006年，Doug Cutting将这些大数据相关的功能从Nutch中分离了出来，然后启动了一个独立的项目专门开发维护大数据技术，这就是后来赫赫有名的Hadoop，主要包括Hadoop分布式文件系统HDFS和大数据计算引擎MapReduce。

Hadoop发布之后，Yahoo很快就用了起来。大概又过了一年到了2007年，百度和阿里巴巴也开始使用Hadoop进行大数据存储与计算。

2008年，Hadoop正式成为Apache的顶级项目，后来Doug Cutting本人也成为了Apache基金会的主席。自此，Hadoop作为软件开发领域的一颗明星冉冉升起。

同年，专门运营Hadoop的商业公司Cloudera成立，Hadoop得到进一步的商业支持。

这个时候，Yahoo的一些人觉得用MapReduce进行大数据编程太麻烦了，于是便开发了Pig。Pig是一种脚本语言，使用类SQL的语法，开发者可以用Pig脚本描述要对大数据集上进行的操作，Pig经过编译后会生成MapReduce程序，然后在Hadoop上运行。

###交互式查询

编写Pig脚本虽然比直接MapReduce编程容易，但是依然需要学习新的脚本语法。于是Facebook又发布了Hive。Hive支持使用SQL语法来进行大数据计算，比如说你可以写个Select语句进行数据查询，然后Hive会把SQL语句转化成MapReduce的计算程序。

这样，熟悉数据库的数据分析师和工程师便可以无门槛地使用大数据进行数据分析和处理了。Hive出现后极大程度地降低了Hadoop的使用难度，迅速得到开发者和企业的追捧。据说，2011年的时候，Facebook大数据平台上运行的作业90%都来源于Hive。

大数据发展史中，谷歌经常扮演“搅局”的角色，这次谷歌发表了一篇论文，介绍了一个叫作 Dremel的系统，也就是现在的 BigQuery。简单来说，BigQuery可以帮助用户很快查到所要的结果。

BigQuery推出后大家都觉得 Hive太慢了，三大 Hadoop分销商都对交互式查询提出了自己的做法。Cloudera做了一个叫作 Impala的项目，这是一个相对蛮成功的产品，到今天还有比较大的影响力；MapR提出了一个叫作 Drill的项目；Hortonworks的做法是干脆努力提高 Hadoop上的查询语言 Hive的查询效率。说到三家公司最后的成长和发展，MapR比较微妙，创始人兼 CTO离开 MapR，成了 Uber的高管；Cloudera和 Hortonworks都已经上市了。

Facebook在 2012年转做了 Presto。Presto查询速度非常快，没有用到 MapReduce。

###后Hadoop时代

随着技术的发展，众多Hadoop周边产品开始出现，大数据生态体系逐渐形成，其中包括：专门将关系数据库中的数据导入导出到Hadoop平台的Sqoop；针对大规模日志进行分布式收集、聚合和传输的Flume；MapReduce工作流调度引擎Oozie等。

在Hadoop早期，MapReduce既是一个执行引擎，又是一个资源调度框架，服务器集群的资源调度管理由MapReduce自己完成。但是这样不利于资源复用，也使得MapReduce非常臃肿。于是一个新项目启动了，将MapReduce执行引擎和资源调度分离开来，这就是Yarn。2012年，Yarn成为一个独立的项目开始运营，随后被各类大数据产品支持，成为大数据平台上最主流的资源调度系统。

同样是在2012年，UC伯克利AMP实验室（Algorithms、Machine和People的缩写）开发的Spark开始崭露头角。当时AMP实验室的马铁博士发现使用MapReduce进行机器学习计算的时候性能非常差，因为机器学习算法通常需要进行很多次的迭代计算，而MapReduce每执行一次Map和Reduce计算都需要重新启动一次作业，带来大量的无谓消耗。还有一点就是MapReduce主要使用磁盘作为存储介质，而2012年的时候，内存已经突破容量和成本限制，成为数据运行过程中主要的存储介质。Spark一经推出，立即受到业界的追捧，并逐步替代MapReduce在企业应用中的地位。

一般说来，像MapReduce、Spark这类计算框架处理的业务场景都被称作批处理计算，因为它们通常针对以“天”为单位产生的数据进行一次计算，然后得到需要的结果，这中间计算需要花费的时间大概是几十分钟甚至更长的时间。因为计算的数据是非在线得到的实时数据，而是历史数据，所以这类计算也被称为大数据离线计算。

而在大数据领域，还有另外一类应用场景，它们需要对实时产生的大量数据进行即时计算，比如对于遍布城市的监控摄像头进行人脸识别和嫌犯追踪。这类计算称为大数据流计算，相应地，有Storm、Flink、Spark Streaming等流计算框架来满足此类大数据应用的场景。 流式计算要处理的数据是实时在线产生的数据，所以这类计算也被称为大数据实时计算。

在典型的大数据的业务场景下，数据业务最通用的做法是，采用批处理的技术处理历史全量数据，采用流式计算处理实时新增数据。而像Flink这样的计算引擎，可以同时支持流式计算和批处理计算。

除了大数据批处理和流处理，NoSQL系统处理的主要也是大规模海量数据的存储与访问，所以也被归为大数据技术。 NoSQL曾经在2011年左右非常火爆，涌现出HBase、Cassandra等许多优秀的产品，其中HBase是从Hadoop中分离出来的、基于HDFS的NoSQL系统。

##明天
大数据时代的有些未来是可以预见的。

第一是数据库能力的提升。谷歌的 Spanner和亚马逊的 Redshift都体现了这种变化：数据库的能力越来越强，它可以解决很多大数据的问题。

第二点是大数据平台的发展非常强调实时性。流计算现在变得非常重要，我个人很看好流计算的发展。

第三点是 AI给大数据准备了什么。谷歌的一篇论文中说到，我们可以通过 AI技术给大数据建立更好的索引。我认为，AI促进大数据发展和大数据融合将来是个很重要的方向
